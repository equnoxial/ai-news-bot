import os, random, feedparser, requests, urllib.parse, time

HF_TOKEN = os.getenv('HF_TOKEN')
TG_TOKEN = os.getenv('TG_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

def get_ai_text(title):
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–Ω—É –∏–∑ —Å–∞–º—ã—Ö —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ HF
    api_url = "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    prompt = f"<|system|>\n–¢—ã ‚Äî –ò–ò-–∂—É—Ä–Ω–∞–ª–∏—Å—Ç. –ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –¥–ª—è Telegram –Ω–∞ —Ä—É—Å—Å–∫–æ–º.<|user|>\n–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ—Å—Ç –ø—Ä–æ —ç—Ç–æ: {title}. –î–æ–±–∞–≤—å —ç–º–æ–¥–∑–∏.<|assistant|>\n"
    
    try:
        print(f"--- –ó–∞–ø—Ä–æ—Å –∫ –ò–ò –¥–ª—è: {title} ---")
        response = requests.post(api_url, headers=headers, json={"inputs": prompt, "parameters": {"max_new_tokens": 200}}, timeout=30)
        if response.status_code == 200:
            res = response.json()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
            raw_text = res[0]['generated_text']
            clean_text = raw_text.split("<|assistant|>\n")[-1].strip()
            if clean_text: 
                print("–ò–ò –æ—Ç–≤–µ—Ç–∏–ª —É—Å–ø–µ—à–Ω–æ!")
                return clean_text
        print(f"–ò–ò –≤—ã–¥–∞–ª –æ—à–∏–±–∫—É {response.status_code}: {response.text}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏ —Å –ò–ò: {e}")
    
    return f"ü§ñ *–ù–û–í–û–°–¢–¨ –ò–ò*\n\n{title}\n\n–ü–æ—Ö–æ–∂–µ, –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å–µ–≥–æ–¥–Ω—è –Ω–µ –≤ –¥—É—Ö–µ, –Ω–æ –Ω–æ–≤–æ—Å—Ç—å –≤–∞–∂–Ω–∞—è!"

def main():
    feed = feedparser.parse("https://techcrunch.com/category/artificial-intelligence/feed/")
    if not feed.entries: return
    entry = feed.entries[0]
    
    # –ß—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç—å—é
    if os.path.exists("last_link.txt"):
        with open("last_link.txt", "r") as f:
            if f.read().strip() == entry.link:
                print("–ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ–∫–∞ –Ω–µ—Ç.")
                return

    post_text = get_ai_text(entry.title)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏
    short_title = " ".join(entry.title.split()[:4])
    encoded = urllib.parse.quote(f"digital artificial intelligence high-tech {short_title}")
    img_url = f"https://image.pollinations.ai/prompt/{encoded}?width=800&height=800&nologo=true&seed={random.randint(1,999)}"
    
    print(f"–°–∫–∞—á–∏–≤–∞—é –∫–∞—Ä—Ç–∏–Ω–∫—É: {img_url}")
    try:
        img_res = requests.get(img_url, timeout=40)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –∏–ª–∏ –º—É—Å–æ—Ä?
        if img_res.status_code == 200 and len(img_res.content) > 5000:
            with open('photo.jpg', 'wb') as f: f.write(img_res.content)
            
            print("–û—Ç–ø—Ä–∞–≤–ª—è—é –≤ Telegram...")
            with open('photo.jpg', 'rb') as photo:
                r = requests.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendPhoto", 
                                 data={"chat_id": CHAT_ID, "caption": post_text, "parse_mode": "Markdown"},
                                 files={"photo": photo})
                if r.status_code == 200:
                    print("–ü–û–ë–ï–î–ê! –ü–æ—Å—Ç —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∏ —Ç–µ–∫—Å—Ç–æ–º —É—à–µ–ª.")
                    with open("last_link.txt", "w") as f: f.write(entry.link)
                    return
        else:
            print("–ö–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ —Å–∫–∞—á–∞–ª–∞—Å—å –∏–ª–∏ –±–∏—Ç–∞—è.")
    except:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π.")

    # –ï—Å–ª–∏ —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π –Ω–µ –≤—ã—à–ª–æ ‚Äî —à–ª–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç
    print("–ü–ª–∞–Ω –ë: —à–ª—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç...")
    requests.post(f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage", 
                 data={"chat_id": CHAT_ID, "text": post_text, "parse_mode": "Markdown"})
    with open("last_link.txt", "w") as f: f.write(entry.link)

if __name__ == "__main__":
    main()
